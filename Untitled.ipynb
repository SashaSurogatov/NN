{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx_labeled_train_fold-0.txt\n",
      "x_train shape: (3200, 256, 256, 1)\n",
      "3200 train samples\n",
      "800 test samples\n",
      "y_train shape: (3200,)\n",
      "[[ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " ..., \n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]]\n",
      "[[ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " ..., \n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]]\n",
      "Train on 3200 samples, validate on 800 samples\n",
      "Epoch 1/12\n",
      "3200/3200 [==============================] - 66s - loss: 3.0231 - acc: 0.5700 - val_loss: 0.6338 - val_acc: 0.5413\n",
      "Epoch 2/12\n",
      "3200/3200 [==============================] - 60s - loss: 0.5435 - acc: 0.7328 - val_loss: 0.4934 - val_acc: 0.7887\n",
      "Epoch 3/12\n",
      "3200/3200 [==============================] - 60s - loss: 0.4951 - acc: 0.7681 - val_loss: 0.4670 - val_acc: 0.8087\n",
      "Epoch 4/12\n",
      "3200/3200 [==============================] - 61s - loss: 0.4460 - acc: 0.7978 - val_loss: 0.3797 - val_acc: 0.8337\n",
      "Epoch 5/12\n",
      "3200/3200 [==============================] - 60s - loss: 0.4066 - acc: 0.8241 - val_loss: 0.3458 - val_acc: 0.8425\n",
      "Epoch 6/12\n",
      "3200/3200 [==============================] - 61s - loss: 0.3824 - acc: 0.8309 - val_loss: 0.3596 - val_acc: 0.8313\n",
      "Epoch 7/12\n",
      "3200/3200 [==============================] - 61s - loss: 0.3670 - acc: 0.8447 - val_loss: 0.2896 - val_acc: 0.8688\n",
      "Epoch 8/12\n",
      "3200/3200 [==============================] - 61s - loss: 0.3142 - acc: 0.8766 - val_loss: 0.2639 - val_acc: 0.8888\n",
      "Epoch 9/12\n",
      "3200/3200 [==============================] - 61s - loss: 0.2893 - acc: 0.8775 - val_loss: 0.2414 - val_acc: 0.8900\n",
      "Epoch 10/12\n",
      "3200/3200 [==============================] - 61s - loss: 0.2793 - acc: 0.8806 - val_loss: 0.2517 - val_acc: 0.8988\n",
      "Epoch 11/12\n",
      "3200/3200 [==============================] - 61s - loss: 0.2426 - acc: 0.9066 - val_loss: 0.2701 - val_acc: 0.8775\n",
      "Epoch 12/12\n",
      "3200/3200 [==============================] - 61s - loss: 0.2308 - acc: 0.9119 - val_loss: 0.1947 - val_acc: 0.9150\n",
      "Test loss: 0.194676298201\n",
      "Test accuracy: 0.915\n",
      "idx_labeled_train_fold-1.txt\n",
      "x_train shape: (3200, 256, 256, 1)\n",
      "3200 train samples\n",
      "800 test samples\n",
      "y_train shape: (3200,)\n",
      "[[ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " ..., \n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]]\n",
      "[[ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " ..., \n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]]\n",
      "Train on 3200 samples, validate on 800 samples\n",
      "Epoch 1/12\n",
      "3200/3200 [==============================] - 61s - loss: 0.2237 - acc: 0.9141 - val_loss: 0.1216 - val_acc: 0.9587\n",
      "Epoch 2/12\n",
      "3200/3200 [==============================] - 61s - loss: 0.2007 - acc: 0.9203 - val_loss: 0.1455 - val_acc: 0.9337\n",
      "Epoch 3/12\n",
      "3200/3200 [==============================] - 61s - loss: 0.2043 - acc: 0.9159 - val_loss: 0.2270 - val_acc: 0.8912\n",
      "Epoch 4/12\n",
      "3200/3200 [==============================] - 61s - loss: 0.1773 - acc: 0.9409 - val_loss: 0.1106 - val_acc: 0.9663\n",
      "Epoch 5/12\n",
      "3200/3200 [==============================] - 61s - loss: 0.1762 - acc: 0.9322 - val_loss: 0.1020 - val_acc: 0.9712\n",
      "Epoch 6/12\n",
      "3200/3200 [==============================] - 61s - loss: 0.1491 - acc: 0.9503 - val_loss: 0.0977 - val_acc: 0.9663\n",
      "Epoch 7/12\n",
      "3200/3200 [==============================] - 61s - loss: 0.1329 - acc: 0.9544 - val_loss: 0.0944 - val_acc: 0.9663\n",
      "Epoch 8/12\n",
      "3200/3200 [==============================] - 61s - loss: 0.1296 - acc: 0.9494 - val_loss: 0.1012 - val_acc: 0.9637\n",
      "Epoch 9/12\n",
      "3200/3200 [==============================] - 61s - loss: 0.1162 - acc: 0.9569 - val_loss: 0.0813 - val_acc: 0.9750\n",
      "Epoch 10/12\n",
      "3200/3200 [==============================] - 61s - loss: 0.1067 - acc: 0.9631 - val_loss: 0.0879 - val_acc: 0.9712\n",
      "Epoch 11/12\n",
      "3200/3200 [==============================] - 61s - loss: 0.0964 - acc: 0.9619 - val_loss: 0.2184 - val_acc: 0.9025\n",
      "Epoch 12/12\n",
      "3200/3200 [==============================] - 61s - loss: 0.1015 - acc: 0.9650 - val_loss: 0.5334 - val_acc: 0.7725\n",
      "Test loss: 0.533363147378\n",
      "Test accuracy: 0.7725\n",
      "idx_labeled_train_fold-2.txt\n",
      "x_train shape: (3200, 256, 256, 1)\n",
      "3200 train samples\n",
      "800 test samples\n",
      "y_train shape: (3200,)\n",
      "[[ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " ..., \n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]]\n",
      "[[ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " ..., \n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]]\n",
      "Train on 3200 samples, validate on 800 samples\n",
      "Epoch 1/12\n",
      "3200/3200 [==============================] - 61s - loss: 0.0973 - acc: 0.9644 - val_loss: 0.0631 - val_acc: 0.9738\n",
      "Epoch 2/12\n",
      "3200/3200 [==============================] - 61s - loss: 0.0823 - acc: 0.9716 - val_loss: 0.0459 - val_acc: 0.9875\n",
      "Epoch 3/12\n",
      "3200/3200 [==============================] - 61s - loss: 0.0724 - acc: 0.9756 - val_loss: 0.0404 - val_acc: 0.9875\n",
      "Epoch 4/12\n",
      "3200/3200 [==============================] - 61s - loss: 0.0673 - acc: 0.9747 - val_loss: 0.0438 - val_acc: 0.9888\n",
      "Epoch 5/12\n",
      "3200/3200 [==============================] - 61s - loss: 0.0653 - acc: 0.9775 - val_loss: 0.0392 - val_acc: 0.9888\n",
      "Epoch 6/12\n",
      "3200/3200 [==============================] - 61s - loss: 0.0744 - acc: 0.9738 - val_loss: 0.0487 - val_acc: 0.9812\n",
      "Epoch 7/12\n",
      "3200/3200 [==============================] - 61s - loss: 0.0471 - acc: 0.9841 - val_loss: 0.0454 - val_acc: 0.9812\n",
      "Epoch 8/12\n",
      "3200/3200 [==============================] - 61s - loss: 0.0529 - acc: 0.9816 - val_loss: 0.0410 - val_acc: 0.9838\n",
      "Epoch 9/12\n",
      "3200/3200 [==============================] - 61s - loss: 0.0429 - acc: 0.9862 - val_loss: 0.0442 - val_acc: 0.9850\n",
      "Epoch 10/12\n",
      "3200/3200 [==============================] - 61s - loss: 0.0447 - acc: 0.9838 - val_loss: 0.0473 - val_acc: 0.9788\n",
      "Epoch 11/12\n",
      "3200/3200 [==============================] - 61s - loss: 0.0325 - acc: 0.9891 - val_loss: 0.0498 - val_acc: 0.9812\n",
      "Epoch 12/12\n",
      "3200/3200 [==============================] - 61s - loss: 0.0507 - acc: 0.9834 - val_loss: 0.0710 - val_acc: 0.9738\n",
      "Test loss: 0.0710253550857\n",
      "Test accuracy: 0.97375\n",
      "800 554 69.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import os\n",
    "#os.environ[\"THEANO_FLAGS\"] = \"mode=FAST_RUN,device=gpu,floatX=float32\"\n",
    "from __future__ import print_function\n",
    "from scipy import misc\n",
    "import numpy as np\n",
    "import keras\n",
    "import h5py as h5py\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "batch_size = 64\n",
    "num_classes = 2\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 256, 256\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(img_rows, img_cols, 1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "path = '../../Data/train-val-splits/2-ages_junior-senior_5-fold/'\n",
    "\n",
    "\n",
    "for i in range(0, 3):\n",
    "    x = []\n",
    "    y = []\n",
    "    xt = []\n",
    "    yt = []\n",
    "\n",
    "    train_file_name = 'idx_labeled_train_fold-%d.txt' % (i)\n",
    "    val_file_name = 'idx_labeled_val_fold-%d.txt' % (i)\n",
    "    print (train_file_name)\n",
    "\n",
    "    f_train = open(path + train_file_name, 'r')\n",
    "    f_val = open(path + val_file_name, 'r')\n",
    "\n",
    "    for line in f_train.readlines():\n",
    "        file_name, class_val = line.split()\n",
    "        image = misc.imread('../../Data/' + file_name)\n",
    "        x.append(image)\n",
    "        y.append(class_val)\n",
    "    \n",
    "    for line in f_val.readlines():\n",
    "        file_name, class_val = line.split()\n",
    "        image = misc.imread('../../Data/' + file_name)\n",
    "        xt.append(image)\n",
    "        yt.append(class_val)\n",
    "\n",
    "    f_train.close()\n",
    "    f_val.close()\n",
    "\n",
    "    x_train = np.array(x)\n",
    "    y_train = np.array(y)\n",
    "    x_test = np.array(xt)\n",
    "    y_test = np.array(yt)\n",
    "\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "\n",
    "    print('y_train shape:', y_train.shape)\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "    print (y_train)\n",
    "    print (y_test)\n",
    "\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=1,\n",
    "              validation_data=(x_test, y_test))\n",
    "\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    \n",
    "model.save('lenet_model.m5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 554 69.25\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "from scipy import misc\n",
    "\n",
    "img_rows, img_cols = 256, 256\n",
    "num_classes = 2\n",
    "\n",
    "model = load_model('lenet_model.m5')\n",
    "\n",
    "path = '../../Data/train-val-splits/2-ages_junior-senior_5-fold/'\n",
    "\n",
    "val_file_name = 'idx_labeled_val_fold-%d.txt' % (4)\n",
    "\n",
    "f_val = open(path + val_file_name, 'r')\n",
    "\n",
    "xt = []\n",
    "yt = []\n",
    "\n",
    "for line in f_val.readlines():\n",
    "    file_name, class_val = line.split()\n",
    "    image = misc.imread('../../Data/' + file_name)\n",
    "    xt.append(image)\n",
    "    yt.append(class_val)\n",
    "    \n",
    "x_test = np.array(xt)\n",
    "y_test = np.array(yt)\n",
    "\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "predicted = model.predict(x_test);\n",
    "\n",
    "correct = 0\n",
    "for i in range(0, predicted.shape[0]):\n",
    "    #print ('X = ', predicted[i,0:], '\\nY = ', y_test[i,0:])\n",
    "    diff = predicted[i,0:] - y_test[i,0:]\n",
    "    if (diff[0] < 1/1e5 and diff[1] < 1/1e5):\n",
    "        correct += 1\n",
    "\n",
    "print (predicted.shape[0], correct, correct * 100 / predicted.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
